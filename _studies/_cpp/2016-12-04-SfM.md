### SfM Method / 변화로 부터 구조 파악하는 방법

SfM : Structure from Motion

#### Refinement of the reconstruction / 재구성한 것 다듬기

* **Bundle Adjustment (BA)** : 무더기로 조정하기(?)

3D 점들의 위치와 카메라의 위치를 동시에 조정하여, reprojection / 재투영 에러를 최소화한다.

근사치로 결정된 3D 점들이 원래의 2D 점들의 위치에 가장 가까운 곳으로 투영(돌출) 된다.

이 때문에 앞에서 각 3D 점군들에 대한 원래 2D 점들의 위치를 지니고 있는 것이다.

* **Simple Sparse Bundle Adjustment (SSBA)**

BA 중에서 간단한 것으로 SSBA가 있다. 

입력 파라미터가 적기 때문에 우리의 자료구조로도 BA를 비교적 쉽게 수행할 수 있다. 

필요한 요소는 카메라 파라미터(instrinsics ?), 3D 점군들, (3D 점군과 관련된) 2D 이미지 점들, 장면을 향하고 있는 카메라들(해당안되는 카메라도 있을 수 있음)이다.

* **Source Code**

```
void BundleAdjuster::adjustBundle(
    vector<CloudPoint> & pointcloud,                        // 3D 점군
    const Mat & cam_intrinsics,                             // 카메라 고유값? (파라미터)
    conststd::vector<std::vector<cv::KeyPoint>> & imgpts,   // 2D 이미지들
    std::map<int ,cv::Matx34d> & Pmats)                     // 카메라들
{
    int N = Pmats.size(), M = pointcloud.size(), K = -1;
    cout<<"N (cams) = "<< N <<" M (points) = "<< M <<" K (measurements) =
    "<< K <<endl;
    
    StdDistortionFunction distortion;
    
    // intrinsic parameters matrix - 카메라 고유값(?) 파라미터를 담는 행렬을 초기화한다.
    Matrix3x3d KMat;
    makeIdentityMatrix(KMat);   // 행렬 초기화
    KMat[0][0] = cam_intrinsics.at<double>(0,0);
    KMat[0][1] = cam_intrinsics.at<double>(0,1);
    KMat[0][2] = cam_intrinsics.at<double>(0,2);
    KMat[1][1] = cam_intrinsics.at<double>(1,1);
    KMat[1][2] = cam_intrinsics.at<double>(1,2);
    ...
    
    // 3D point cloud - 3D 점군 위치를 담는 벡터 x 를 만든다. 개수는 점군의 개수이다.
    vector<Vector3d >Xs(M);
    for (int j = 0; j < M; ++j)
    {
        Xs[j][0] = pointcloud[j].pt.x;
        Xs[j][1] = pointcloud[j].pt.y;
        Xs[j][2] = pointcloud[j].pt.z;
    }
    cout<<"Read the 3D points."<<endl;
    
    // convert cameras to BA datastructs - N개의 카메라(행렬로 표현)를 담고 있는 벡터를 만든다.
    vector<CameraMatrix> cams(N);
    for (inti = 0; i< N; ++i)
    {
        intcamId = i;           // 카메라 번호(id)
        Matrix3x3d R;           // 카메라 회전 행렬
        Vector3d T;             // 카메라 위치(방향?) 벡터
        Matx34d& P = Pmats[i];  // 각 카메라에 대한 변환 행렬을 저장하는 행렬
        
        R[0][0] = P(0,0); R[0][1] = P(0,1); R[0][2] = P(0,2); T[0] = P(0,3);
        R[1][0] = P(1,0); R[1][1] = P(1,1); R[1][2] = P(1,2); T[1] = P(1,3);
        R[2][0] = P(2,0); R[2][1] = P(2,1); R[2][2] = P(2,2); T[2] = P(2,3);
        
        cams[i].setIntrinsic(Knorm);        // K norm - K : 카메라 고유값(?)의 놈
        cams[i].setRotation(R);
        cams[i].setTranslation(T);
    }
    
    cout<<"Read the cameras."<<endl;
    vector<Vector2d > measurements;
    vector<int> correspondingView;
    vector<int> correspondingPoint;
    
    // 2D corresponding points
    for (unsigned int k = 0; k <pointcloud.size(); ++k) // 모든 3D 점군에 대해
    {                                                   // 관련된 2D 점들을 구함(?)
        for (unsigned int i=0; i<pointcloud[k].imgpt_for_img.size(); i++) {
            if (pointcloud[k].imgpt_for_img[i] >= 0) {
                int view = i, point = k;
                Vector3d p, np;
                
                Point cvp = imgpts[i][pointcloud[k].imgpt_for_img[i]].pt;
                p[0] = cvp.x;
                p[1] = cvp.y;
                p[2] = 1.0;                             // 2D 이미지는 z값 없음
                
                // Normalize the measurements to match the unit focal length.
                scaleVectorIP(1.0/f0, p);
                measurements.push_back(Vector2d(p[0], p[1]));
                correspondingView.push_back(view);
                correspondingPoint.push_back(point);
            }
        }
    } // end for (k)
    K = measurements.size();
    cout<<"Read "<< K <<" valid 2D measurements."<<endl;
    ...
    // perform the bundle adjustment - 어떻게 하는지는 함수를 열어봐야 알 듯함. ㅜㅜ
    {
        CommonInternalsMetricBundleOptimizeropt(V3D::FULL_BUNDLE_FOCAL_LENGTH_PP,
                                                inlierThreshold, K0, distortion, cams, Xs,
                                                measurements, correspondingView, correspondingPoint);
        opt.tau = 1e-3;
        opt.maxIterations = 50;
        opt.minimize();
        cout<<"optimizer status = "<<opt.status<<endl;
    }
    ...
    //extract 3D points - 3D 점군들의 위치를 새로 저장
    for (unsigned int j = 0; j <Xs.size(); ++j)
    {
        pointcloud[j].pt.x = Xs[j][0];
        
        pointcloud[j].pt.y = Xs[j][1];
        pointcloud[j].pt.z = Xs[j][2];
    }
    //extract adjusted cameras - 각 카메라의 위치 및 방향을 새로 저장
    for (int i = 0; i< N; ++i)
    {
        Matrix3x3d R = cams[i].getRotation();
        Vector3d T = cams[i].getTranslation();
        Matx34d P;
        P(0,0) = R[0][0]; P(0,1) = R[0][1]; P(0,2) = R[0][2]; P(0,3) = T[0];
        P(1,0) = R[1][0]; P(1,1) = R[1][1]; P(1,2) = R[1][2]; P(1,3) = T[1];
        P(2,0) = R[2][0]; P(2,1) = R[2][1]; P(2,2) = R[2][2]; P(2,3) = T[2];
        Pmats[i] = P;
    }
}
```


